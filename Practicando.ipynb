{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd55b2e0",
   "metadata": {},
   "source": [
    "**Trabajo Final Tratamiento de Datos**\n",
    "Jorge Gabriel Sampedro    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ebec0",
   "metadata": {},
   "source": [
    "*RED NEURONAL CONVOLUCIONAL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06be103c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c33d1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.3-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-win_amd64.whl (55 kB)\n",
      "     -------------------------------------- 55.4/55.4 kB 960.5 kB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jorge\\anaconda3\\envs\\proyecto1\\lib\\site-packages (from matplotlib) (1.23.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jorge\\anaconda3\\envs\\proyecto1\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jorge\\anaconda3\\envs\\proyecto1\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.37.1-py3-none-any.whl (957 kB)\n",
      "     -------------------------------------- 957.2/957.2 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jorge\\anaconda3\\envs\\proyecto1\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.2.0-cp38-cp38-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jorge\\anaconda3\\envs\\proyecto1\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.37.1 kiwisolver-1.4.4 matplotlib-3.5.3 pillow-9.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0397f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0453d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e086faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a8a223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4051975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de  C:\\Users\\Jorge\\Documents\\Ciberseguridad\\Tratamiento de datos\\final\\train\\\n",
      "C:\\Users\\Jorge\\Documents\\Ciberseguridad\\Tratamiento de datos\\final\\train\\CLASS_02 1\n",
      "C:\\Users\\Jorge\\Documents\\Ciberseguridad\\Tratamiento de datos\\final\\train\\CLASS_03 62\n",
      "C:\\Users\\Jorge\\Documents\\Ciberseguridad\\Tratamiento de datos\\final\\train\\CLASS_04 213\n",
      "C:\\Users\\Jorge\\Documents\\Ciberseguridad\\Tratamiento de datos\\final\\train\\CLASS_05 105\n",
      "C:\\Users\\Jorge\\Documents\\Ciberseguridad\\Tratamiento de datos\\final\\train\\CLASS_06 949\n",
      "C:\\Users\\Jorge\\Documents\\Ciberseguridad\\Tratamiento de datos\\final\\train\\CLASS_07 37\n",
      "C:\\Users\\Jorge\\Documents\\Ciberseguridad\\Tratamiento de datos\\final\\train\\CLASS_08 204\n",
      "Directorios leidos: 7\n",
      "Imagenes en cada directorio [63, 213, 105, 949, 37, 204, 62]\n",
      "suma Total de imagenes en subdirs: 1633\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.join(os.getcwd(), 'train')\n",
    "imgpath = dirname + os.sep \n",
    " \n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    " \n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    " \n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant=cant+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images.append(image)\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant)\n",
    "                prevRoot=root\n",
    "                directories.append(root)\n",
    "                dircount.append(cant)\n",
    "                cant=0\n",
    "dircount.append(cant)\n",
    " \n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d59303ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  1633\n",
      "0 CLASS_02\n",
      "1 CLASS_03\n",
      "2 CLASS_04\n",
      "3 CLASS_05\n",
      "4 CLASS_06\n",
      "5 CLASS_07\n",
      "6 CLASS_08\n",
      "Total number of outputs :  7\n",
      "Output classes :  [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
    " \n",
    "carnes=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    carnes.append(name[len(name)-1])\n",
    "    indice=indice+1\n",
    " \n",
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8) #para crear la lista a numpy\n",
    " \n",
    "# Los número de las etiquetas\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa4ccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1469, 216, 384, 3) (1469,)\n",
      "Testing data shape :  (164, 216, 384, 3) (164,)\n"
     ]
    }
   ],
   "source": [
    "#Permutación aleatoria entre datos de validación y de test\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.1)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d65d82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth : 3')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    " \n",
    "# Cambiar las etiquetas de categorical a one hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Mostrar la primera imagen del entrenamiento en grises\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_Y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05be2a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 3\n",
      "After conversion to one-hot: [0. 0. 0. 1. 0. 0. 0.]\n",
      "(1322, 216, 384, 3) (147, 216, 384, 3) (1322, 7) (147, 7)\n"
     ]
    }
   ],
   "source": [
    "#Mostrar el cambio\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
    " \n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.1, random_state=13)\n",
    " \n",
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fba33b",
   "metadata": {},
   "source": [
    "Definir la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a3041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d419bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90b67b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cd429d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "carnes_model = Sequential()\n",
    "carnes_model.add(Convolution2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(216,384,3)))\n",
    "carnes_model.add(LeakyReLU(alpha=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35c1117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "carnes_model.add(Flatten())\n",
    "carnes_model.add(Dense(32, activation='linear'))\n",
    "carnes_model.add(LeakyReLU(alpha=0.1))\n",
    "carnes_model.add(Dropout(0.5)) \n",
    "carnes_model.add(Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c7457aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 216, 384, 32)      896       \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 216, 384, 32)      0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2654208)           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                84934688  \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,935,815\n",
      "Trainable params: 84,935,815\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "carnes_model.summary()\n",
    " \n",
    "carnes_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(learning_rate=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9128950",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'carnes_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m carnes_train_dropout \u001b[38;5;241m=\u001b[39m \u001b[43mcarnes_model\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train_X, train_label, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,epochs\u001b[38;5;241m=\u001b[39mepochs,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,validation_data\u001b[38;5;241m=\u001b[39m(valid_X, valid_label))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# guardamos la red para usarla en un futuro, sin la necesidad de volver a entrenar la red.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m carnes_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarnes_mnist.h5py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'carnes_model' is not defined"
     ]
    }
   ],
   "source": [
    "carnes_train_dropout = carnes_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    " \n",
    "# guardamos la red para usarla en un futuro, sin la necesidad de volver a entrenar la red.\n",
    "carnes_model.save(\"carnes_mnist.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc99c57f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 7s 511ms/step - loss: 1.2288 - accuracy: 0.6585\n",
      "Test loss: 1.2287826538085938\n",
      "Test accuracy: 0.6585366129875183\n"
     ]
    }
   ],
   "source": [
    "test_eval = carnes_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    " \n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
